@@@ A - classifier: DummyClassifier(constant=1, random_state=None, strategy='constant')
@@@ B - threshold stop at: 1
@@@ C - Repeat number: 1
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
iter: 0, sample_no: 1860, actual label: 1, predicted: 1
iter: 1, sample_no: 2106, actual label: 1, predicted: 1
iter: 2, sample_no: 786, actual label: 1, predicted: 1
iter: 3, sample_no: 498, actual label: 0, predicted: 1
iter: 4, sample_no: 2482, actual label: 1, predicted: 1
iter: 5, sample_no: 1063, actual label: 1, predicted: 1
iter: 6, sample_no: 89, actual label: 0, predicted: 1
iter: 7, sample_no: 210, actual label: 1, predicted: 1
iter: 8, sample_no: 1876, actual label: 1, predicted: 1
iter: 9, sample_no: 1646, actual label: 1, predicted: 1
iter: 10, sample_no: 1195, actual label: 1, predicted: 1
iter: 11, sample_no: 1330, actual label: 1, predicted: 1
iter: 12, sample_no: 844, actual label: 1, predicted: 1
iter: 13, sample_no: 2318, actual label: 1, predicted: 1
iter: 14, sample_no: 173, actual label: 0, predicted: 1
iter: 15, sample_no: 484, actual label: 0, predicted: 1
iter: 16, sample_no: 477, actual label: 1, predicted: 1
iter: 17, sample_no: 2328, actual label: 1, predicted: 1
iter: 18, sample_no: 516, actual label: 0, predicted: 1
iter: 19, sample_no: 389, actual label: 0, predicted: 1
iter: 20, sample_no: 2012, actual label: 1, predicted: 1
iter: 21, sample_no: 1449, actual label: 1, predicted: 1
iter: 22, sample_no: 2544, actual label: 1, predicted: 1
iter: 23, sample_no: 1003, actual label: 0, predicted: 1
iter: 24, sample_no: 1610, actual label: 1, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
@@@ C - Repeat number: 2
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
iter: 0, sample_no: 1812, actual label: 1, predicted: 1
iter: 1, sample_no: 1626, actual label: 1, predicted: 1
iter: 2, sample_no: 1822, actual label: 1, predicted: 1
iter: 3, sample_no: 2342, actual label: 1, predicted: 1
iter: 4, sample_no: 1185, actual label: 1, predicted: 1
iter: 5, sample_no: 2083, actual label: 1, predicted: 1
iter: 6, sample_no: 193, actual label: 1, predicted: 1
iter: 7, sample_no: 1710, actual label: 1, predicted: 1
iter: 8, sample_no: 1803, actual label: 1, predicted: 1
iter: 9, sample_no: 564, actual label: 0, predicted: 1
iter: 10, sample_no: 1186, actual label: 1, predicted: 1
iter: 11, sample_no: 615, actual label: 0, predicted: 1
iter: 12, sample_no: 1643, actual label: 1, predicted: 1
iter: 13, sample_no: 260, actual label: 0, predicted: 1
iter: 14, sample_no: 619, actual label: 0, predicted: 1
iter: 15, sample_no: 1340, actual label: 1, predicted: 1
iter: 16, sample_no: 41, actual label: 0, predicted: 1
iter: 17, sample_no: 2214, actual label: 1, predicted: 1
iter: 18, sample_no: 994, actual label: 1, predicted: 1
iter: 19, sample_no: 1352, actual label: 0, predicted: 1
iter: 20, sample_no: 464, actual label: 0, predicted: 1
iter: 21, sample_no: 198, actual label: 1, predicted: 1
iter: 22, sample_no: 111, actual label: 0, predicted: 1
iter: 23, sample_no: 543, actual label: 0, predicted: 1
iter: 24, sample_no: 691, actual label: 0, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
@@@ C - Repeat number: 3
/Users/author1/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:463: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint8 = np.dtype([("qint8", np.int8, 1)])
/Users/author1/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:464: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint8 = np.dtype([("quint8", np.uint8, 1)])
/Users/author1/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:465: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint16 = np.dtype([("qint16", np.int16, 1)])
/Users/author1/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:466: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_quint16 = np.dtype([("quint16", np.uint16, 1)])
/Users/author1/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/dtypes.py:467: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.
  _np_qint32 = np.dtype([("qint32", np.int32, 1)])
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
iter: 0, sample_no: 2462, actual label: 1, predicted: 1
iter: 1, sample_no: 2493, actual label: 1, predicted: 1
iter: 2, sample_no: 1363, actual label: 0, predicted: 1
iter: 3, sample_no: 1637, actual label: 1, predicted: 1
iter: 4, sample_no: 590, actual label: 0, predicted: 1
iter: 5, sample_no: 1863, actual label: 1, predicted: 1
iter: 6, sample_no: 2174, actual label: 1, predicted: 1
iter: 7, sample_no: 1081, actual label: 1, predicted: 1
iter: 8, sample_no: 317, actual label: 0, predicted: 1
iter: 9, sample_no: 349, actual label: 0, predicted: 1
iter: 10, sample_no: 1959, actual label: 1, predicted: 1
iter: 11, sample_no: 1974, actual label: 1, predicted: 1
iter: 12, sample_no: 1887, actual label: 1, predicted: 1
iter: 13, sample_no: 710, actual label: 1, predicted: 1
iter: 14, sample_no: 1751, actual label: 1, predicted: 1
iter: 15, sample_no: 1199, actual label: 1, predicted: 1
iter: 16, sample_no: 1926, actual label: 1, predicted: 1
iter: 17, sample_no: 1145, actual label: 1, predicted: 1
iter: 18, sample_no: 2192, actual label: 1, predicted: 1
iter: 19, sample_no: 1967, actual label: 1, predicted: 1
iter: 20, sample_no: 132, actual label: 0, predicted: 1
iter: 21, sample_no: 1496, actual label: 0, predicted: 1
iter: 22, sample_no: 463, actual label: 0, predicted: 1
iter: 23, sample_no: 2541, actual label: 0, predicted: 1
iter: 24, sample_no: 3, actual label: 1, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
@@@ C - Repeat number: 4
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
iter: 0, sample_no: 1576, actual label: 1, predicted: 1
iter: 1, sample_no: 398, actual label: 0, predicted: 1
iter: 2, sample_no: 2458, actual label: 1, predicted: 1
iter: 3, sample_no: 1308, actual label: 1, predicted: 1
iter: 4, sample_no: 1034, actual label: 0, predicted: 1
iter: 5, sample_no: 228, actual label: 0, predicted: 1
iter: 6, sample_no: 1961, actual label: 1, predicted: 1
iter: 7, sample_no: 1338, actual label: 1, predicted: 1
iter: 8, sample_no: 1320, actual label: 0, predicted: 1
iter: 9, sample_no: 1707, actual label: 1, predicted: 1
iter: 10, sample_no: 1061, actual label: 1, predicted: 1
iter: 11, sample_no: 1487, actual label: 0, predicted: 1
iter: 12, sample_no: 1633, actual label: 1, predicted: 1
iter: 13, sample_no: 1793, actual label: 1, predicted: 1
iter: 14, sample_no: 2498, actual label: 1, predicted: 1
iter: 15, sample_no: 2224, actual label: 1, predicted: 1
iter: 16, sample_no: 1508, actual label: 0, predicted: 1
iter: 17, sample_no: 2360, actual label: 1, predicted: 1
iter: 18, sample_no: 1728, actual label: 1, predicted: 1
iter: 19, sample_no: 77, actual label: 0, predicted: 1
iter: 20, sample_no: 1183, actual label: 1, predicted: 1
iter: 21, sample_no: 1733, actual label: 1, predicted: 1
iter: 22, sample_no: 1966, actual label: 1, predicted: 1
iter: 23, sample_no: 394, actual label: 0, predicted: 1
iter: 24, sample_no: 768, actual label: 1, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
@@@ C - Repeat number: 5
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
iter: 0, sample_no: 1159, actual label: 1, predicted: 1
iter: 1, sample_no: 286, actual label: 0, predicted: 1
iter: 2, sample_no: 1329, actual label: 1, predicted: 1
iter: 3, sample_no: 764, actual label: 1, predicted: 1
iter: 4, sample_no: 1082, actual label: 1, predicted: 1
iter: 5, sample_no: 1938, actual label: 1, predicted: 1
iter: 6, sample_no: 47, actual label: 0, predicted: 1
iter: 7, sample_no: 2276, actual label: 1, predicted: 1
iter: 8, sample_no: 2008, actual label: 1, predicted: 1
iter: 9, sample_no: 704, actual label: 0, predicted: 1
iter: 10, sample_no: 880, actual label: 1, predicted: 1
iter: 11, sample_no: 1569, actual label: 1, predicted: 1
iter: 12, sample_no: 1936, actual label: 1, predicted: 1
iter: 13, sample_no: 245, actual label: 0, predicted: 1
iter: 14, sample_no: 1140, actual label: 1, predicted: 1
iter: 15, sample_no: 1982, actual label: 1, predicted: 1
iter: 16, sample_no: 1386, actual label: 1, predicted: 1
iter: 17, sample_no: 395, actual label: 0, predicted: 1
iter: 18, sample_no: 552, actual label: 0, predicted: 1
iter: 19, sample_no: 2140, actual label: 1, predicted: 1
iter: 20, sample_no: 1048, actual label: 1, predicted: 1
iter: 21, sample_no: 925, actual label: 1, predicted: 1
iter: 22, sample_no: 2496, actual label: 0, predicted: 1
iter: 23, sample_no: 640, actual label: 0, predicted: 1
iter: 24, sample_no: 142, actual label: 0, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
@@@ C - Repeat number: 6
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
iter: 0, sample_no: 1361, actual label: 1, predicted: 1
iter: 1, sample_no: 2131, actual label: 1, predicted: 1
iter: 2, sample_no: 2320, actual label: 1, predicted: 1
iter: 3, sample_no: 1620, actual label: 1, predicted: 1
iter: 4, sample_no: 1637, actual label: 1, predicted: 1
iter: 5, sample_no: 1242, actual label: 1, predicted: 1
iter: 6, sample_no: 1819, actual label: 1, predicted: 1
iter: 7, sample_no: 903, actual label: 1, predicted: 1
iter: 8, sample_no: 552, actual label: 0, predicted: 1
iter: 9, sample_no: 1924, actual label: 1, predicted: 1
iter: 10, sample_no: 982, actual label: 1, predicted: 1
iter: 11, sample_no: 781, actual label: 1, predicted: 1
iter: 12, sample_no: 2224, actual label: 1, predicted: 1
iter: 13, sample_no: 139, actual label: 0, predicted: 1
iter: 14, sample_no: 776, actual label: 1, predicted: 1
iter: 15, sample_no: 1195, actual label: 1, predicted: 1
iter: 16, sample_no: 1903, actual label: 1, predicted: 1
iter: 17, sample_no: 1574, actual label: 1, predicted: 1
iter: 18, sample_no: 2026, actual label: 1, predicted: 1
iter: 19, sample_no: 1786, actual label: 1, predicted: 1
iter: 20, sample_no: 2093, actual label: 1, predicted: 1
iter: 21, sample_no: 2478, actual label: 1, predicted: 1
iter: 22, sample_no: 601, actual label: 0, predicted: 1
iter: 23, sample_no: 1807, actual label: 1, predicted: 1
iter: 24, sample_no: 1618, actual label: 1, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
@@@ C - Repeat number: 7
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
iter: 0, sample_no: 426, actual label: 0, predicted: 1
iter: 1, sample_no: 321, actual label: 1, predicted: 1
iter: 2, sample_no: 1325, actual label: 1, predicted: 1
iter: 3, sample_no: 1194, actual label: 1, predicted: 1
iter: 4, sample_no: 1190, actual label: 1, predicted: 1
iter: 5, sample_no: 2468, actual label: 1, predicted: 1
iter: 6, sample_no: 733, actual label: 1, predicted: 1
iter: 7, sample_no: 1888, actual label: 1, predicted: 1
iter: 8, sample_no: 1921, actual label: 1, predicted: 1
iter: 9, sample_no: 453, actual label: 0, predicted: 1
iter: 10, sample_no: 2393, actual label: 1, predicted: 1
iter: 11, sample_no: 2540, actual label: 0, predicted: 1
iter: 12, sample_no: 40, actual label: 0, predicted: 1
iter: 13, sample_no: 1467, actual label: 1, predicted: 1
iter: 14, sample_no: 1155, actual label: 1, predicted: 1
iter: 15, sample_no: 2036, actual label: 1, predicted: 1
iter: 16, sample_no: 2028, actual label: 1, predicted: 1
iter: 17, sample_no: 1927, actual label: 1, predicted: 1
iter: 18, sample_no: 1127, actual label: 1, predicted: 1
iter: 19, sample_no: 608, actual label: 0, predicted: 1
iter: 20, sample_no: 2206, actual label: 1, predicted: 1
iter: 21, sample_no: 578, actual label: 0, predicted: 1
iter: 22, sample_no: 978, actual label: 1, predicted: 1
iter: 23, sample_no: 2304, actual label: 1, predicted: 1
iter: 24, sample_no: 685, actual label: 0, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
@@@ C - Repeat number: 8
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
iter: 0, sample_no: 1712, actual label: 1, predicted: 1
iter: 1, sample_no: 2514, actual label: 1, predicted: 1
iter: 2, sample_no: 2378, actual label: 1, predicted: 1
iter: 3, sample_no: 1590, actual label: 1, predicted: 1
iter: 4, sample_no: 1928, actual label: 1, predicted: 1
iter: 5, sample_no: 97, actual label: 0, predicted: 1
iter: 6, sample_no: 1229, actual label: 1, predicted: 1
iter: 7, sample_no: 265, actual label: 0, predicted: 1
iter: 8, sample_no: 1740, actual label: 1, predicted: 1
iter: 9, sample_no: 1544, actual label: 0, predicted: 1
iter: 10, sample_no: 785, actual label: 1, predicted: 1
iter: 11, sample_no: 851, actual label: 1, predicted: 1
iter: 12, sample_no: 1517, actual label: 0, predicted: 1
iter: 13, sample_no: 2372, actual label: 1, predicted: 1
iter: 14, sample_no: 1326, actual label: 1, predicted: 1
iter: 15, sample_no: 657, actual label: 0, predicted: 1
iter: 16, sample_no: 528, actual label: 0, predicted: 1
iter: 17, sample_no: 1582, actual label: 1, predicted: 1
iter: 18, sample_no: 1224, actual label: 1, predicted: 1
iter: 19, sample_no: 1602, actual label: 1, predicted: 1
iter: 20, sample_no: 1689, actual label: 1, predicted: 1
iter: 21, sample_no: 789, actual label: 1, predicted: 1
iter: 22, sample_no: 2501, actual label: 1, predicted: 1
iter: 23, sample_no: 512, actual label: 0, predicted: 1
iter: 24, sample_no: 2439, actual label: 1, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
@@@ C - Repeat number: 9
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
iter: 0, sample_no: 2105, actual label: 1, predicted: 1
iter: 1, sample_no: 507, actual label: 0, predicted: 1
iter: 2, sample_no: 1658, actual label: 1, predicted: 1
iter: 3, sample_no: 79, actual label: 0, predicted: 1
iter: 4, sample_no: 1314, actual label: 1, predicted: 1
iter: 5, sample_no: 112, actual label: 0, predicted: 1
iter: 6, sample_no: 1102, actual label: 1, predicted: 1
iter: 7, sample_no: 1393, actual label: 0, predicted: 1
iter: 8, sample_no: 154, actual label: 0, predicted: 1
iter: 9, sample_no: 776, actual label: 1, predicted: 1
iter: 10, sample_no: 1423, actual label: 0, predicted: 1
iter: 11, sample_no: 544, actual label: 0, predicted: 1
iter: 12, sample_no: 877, actual label: 1, predicted: 1
iter: 13, sample_no: 1922, actual label: 1, predicted: 1
iter: 14, sample_no: 2338, actual label: 1, predicted: 1
iter: 15, sample_no: 470, actual label: 0, predicted: 1
iter: 16, sample_no: 2555, actual label: 1, predicted: 1
iter: 17, sample_no: 402, actual label: 0, predicted: 1
iter: 18, sample_no: 326, actual label: 0, predicted: 1
iter: 19, sample_no: 1963, actual label: 1, predicted: 1
iter: 20, sample_no: 945, actual label: 1, predicted: 1
iter: 21, sample_no: 1704, actual label: 1, predicted: 1
iter: 22, sample_no: 303, actual label: 0, predicted: 1
iter: 23, sample_no: 1365, actual label: 1, predicted: 1
iter: 24, sample_no: 1387, actual label: 1, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
@@@ C - Repeat number: 10
@@@ D - common_header:  {'F71-vasia@apache.org', 'F3-NA', 'F41', 'F3-Double', 'F71-uce@apache.org', 'F15-NA', 'F71-lungu.andra@gmail.com', 'F123', 'F3-T', 'F77', 'F15-private', 'F65', 'F71-twalthr@apache.org', 'F71-code@greghogan.com', 'F3-String', 'F22', 'F3-double', 'F116', 'F126', 'F71-mxm@apache.org', 'F72', 'F71-rmetzger@apache.org', 'F117', 'F3-int', 'F71-aljoscha.krettek@gmail.com', 'F15-public', 'F3-Values', 'F3-Tuple2', 'F115', 'F3-boolean', 'F71-chesnay@apache.org', 'category', 'F101', 'F120', 'F25', 'F110', 'F3-byte', 'F104', 'F3-Class', 'F3-BooleanValue', 'F15-protected', 'F68', 'F105', 'F71-sewen@apache.org', 'F71-vasilikikalavri@gmail.com', 'F71-fhueske@apache.org', 'F71-trohrmann@apache.org'}
     F72           ...            F71-trohrmann@apache.org
1  19805           ...                                   1
2  19805           ...                                   1
3  19805           ...                                   1

[3 rows x 46 columns]
;.;
        F72            ...             F71-trohrmann@apache.org
0  0.851521            ...                                  1.0
1  0.851521            ...                                  1.0
2  0.851521            ...                                  1.0

[3 rows x 46 columns]
training_x: (2815, 46)
training_y: 2815
testset_x: (2561, 46)
testset_y: 2561
              precision    recall  f1-score   support

           0       0.00      0.00      0.00       780
           1       0.70      1.00      0.82      1781

    accuracy                           0.70      2561
   macro avg       0.35      0.50      0.41      2561
weighted avg       0.48      0.70      0.57      2561

accuracy: 0.6954314720812182
0.8203592814371258
@@@ tn: 0, fp: 780, fn: 0, tp: 1781
@@@ LIME - Creating explainer
@@@ LIME - Random Sampling of Instances
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,271,273,274,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342) have mixed types. Specify dtype option on import or set low_memory=False.
Columns (0,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,41,42,43,44,45,46,47,48,49,50,51,52,53,54,55,56,57,58,59,60,61,62,63,64,65,66,67,68,69,70,71,72,73,74,75,76,77,78,79,80,81,82,83,84,85,86,87,88,89,90,91,92,93,94,95,96,97,98,99,100,101,102,103,104,105,106,107,108,109,110,111,112,113,114,115,116,117,118,119,120,121,122,123,124,125,126,127,128,129,130,131,132,133,134,135,136,137,138,139,140,141,142,143,144,145,146,147,148,149,150,151,152,153,154,155,156,157,158,159,160,161,162,163,164,165,166,167,168,169,170,171,172,173,174,175,176,177,178,179,180,181,182,183,184,185,186,187,188,189,190,191,192,193,194,195,196,197,198,199,200,201,202,203,204,205,206,207,208,209,210,211,212,213,214,215,216,217,218,219,220,221,222,223,224,225,226,227,228,229,230,231,232,233,234,235,236,237,238,239,240,241,242,243,244,245,246,247,248,249,250,251,252,253,254,255,256,257,258,259,260,261,262,263,264,265,266,267,268,269,270,271,273,275,276,277,278,279,280,281,282,283,284,285,286,287,288,289,290,291,292,293,294,295,296,297,298,299,300,301,302,303,304,305,306,307,308,309,310,311,312,313,314,315,316,317,318,319,320,321,322,323,324,325,326,327,328,329,330,331,332,333,334,335,336,337,338,339,340,341,342,343,344) have mixed types. Specify dtype option on import or set low_memory=False.
Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
iter: 0, sample_no: 1692, actual label: 1, predicted: 1
iter: 1, sample_no: 1622, actual label: 1, predicted: 1
iter: 2, sample_no: 1105, actual label: 1, predicted: 1
iter: 3, sample_no: 2029, actual label: 1, predicted: 1
iter: 4, sample_no: 1997, actual label: 1, predicted: 1
iter: 5, sample_no: 2215, actual label: 1, predicted: 1
iter: 6, sample_no: 2237, actual label: 1, predicted: 1
iter: 7, sample_no: 148, actual label: 0, predicted: 1
iter: 8, sample_no: 550, actual label: 0, predicted: 1
iter: 9, sample_no: 780, actual label: 1, predicted: 1
iter: 10, sample_no: 445, actual label: 0, predicted: 1
iter: 11, sample_no: 309, actual label: 0, predicted: 1
iter: 12, sample_no: 2349, actual label: 1, predicted: 1
iter: 13, sample_no: 2201, actual label: 1, predicted: 1
iter: 14, sample_no: 2040, actual label: 1, predicted: 1
iter: 15, sample_no: 896, actual label: 1, predicted: 1
iter: 16, sample_no: 1595, actual label: 1, predicted: 1
iter: 17, sample_no: 1917, actual label: 1, predicted: 1
iter: 18, sample_no: 1148, actual label: 1, predicted: 1
iter: 19, sample_no: 303, actual label: 0, predicted: 1
iter: 20, sample_no: 1417, actual label: 1, predicted: 1
iter: 21, sample_no: 1599, actual label: 1, predicted: 1
iter: 22, sample_no: 2345, actual label: 1, predicted: 1
iter: 23, sample_no: 1472, actual label: 0, predicted: 1
iter: 24, sample_no: 1085, actual label: 1, predicted: 1
number of samples: 2561
AUC 0.5
pos_get 1781
total recall stop_at 1.0
----------threshold stop at----------: 1
AUC [0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5, 0.5]
AUC_median 0.5
AUC_iqr 0.0
cost [1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]
COST_med 1.0
COST_iqr 0.0
f1_pos_list [0.8203592814371258, 0.8203592814371258, 0.8203592814371258, 0.8203592814371258, 0.8203592814371258, 0.8203592814371258, 0.8203592814371258, 0.8203592814371258, 0.8203592814371258, 0.8203592814371258]
f1_pos_med 0.8203592814371258
